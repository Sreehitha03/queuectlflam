# ‚öôÔ∏è QueueCTL: A Persistent, CLI-Based Background Job Queue System (Python)

**QueueCTL** is a minimal, production-grade background job queue system built in **Python**.  
It reliably executes background shell commands using **concurrent workers**, **automatic retries** with exponential backoff, and **persistent storage** that survives restarts.

---

## üöÄ Features

‚úÖ Command-Line Interface built with **Python Click**  
‚úÖ **Persistent job storage** using SQLite (`queuectl.db`)  
‚úÖ **Concurrent worker execution** via Python‚Äôs Multiprocessing  
‚úÖ **Automatic retry** with configurable exponential backoff  
‚úÖ **Dead Letter Queue (DLQ)** for permanently failed jobs  
‚úÖ **Race-condition safety** through atomic job acquisition  
‚úÖ **Cross-platform input robustness** via STDIN-based JSON input  

---

## üîó Submission Details

| Requirement | Status | Implementation Detail |
|-----------------------------|--------------|------------------------|
| **Working CLI Application** | ‚úÖ Complete | All commands implemented using **Python Click** |
| **Persistent Job Storage**  | ‚úÖ Complete | Data stored using **SQLite** |
| **Multiple Worker Support** | ‚úÖ Complete | Uses **Multiprocessing** for true parallelism |
| **Retry & DLQ Support**     | ‚úÖ Complete | Exponential backoff and permanent DLQ storage |
| **Concurrency Safety**      | ‚úÖ Fixed    | Atomic acquisition + race condition mitigation |
| **Input Robustness**        | ‚úÖ Fixed    | Jobs enqueued through **STDIN** for safe JSON handling |
 
üé• **Demo Video:** _[Add your video demo link here]_  

---

## Architecture Overview

### Concurrency & Reliability
- **Atomic Job Acquisition** ensures that no two workers process the same job simultaneously.  
- A minor `time.sleep(0.05)` ensures **database writes are fully committed** before other workers attempt job acquisition, preventing duplicate execution.  
- Job states and configuration are stored in **SQLite**, providing **data persistence** across application restarts.

### üïì Job Lifecycle & Backoff Logic

Jobs follow this lifecycle:  
`pending ‚Üí processing ‚Üí completed / failed / dead`

| State | Transition Condition | Delay (Backoff Formula) |
|--------|----------------------|--------------------------|
| **pending**        | Job created | ‚Äî |
| **processing**     | Worker starts executing the job | ‚Äî |
| **failed (retry)** | Job fails and `attempts ‚â§ max_retries` | Delay = `base^attempts` seconds |
| **dead (DLQ)**     | Job fails and `attempts > max_retries` | Moved to DLQ |
| **completed**      | Command succeeds | ‚Äî |


### üßæ Usage Instructions

Use STDIN for enqueuing JSON jobs to avoid shell quoting issues across platforms.

Command     Type	    Example Command
Enqueue     Job	        echo '{"id":"job1","command":"echo Hello"}' | python -m src.cli enqueue
Check       Status	    python -m src.cli status
Start       Worker(s)	python -m src.cli worker start --count 2
View        DLQ Jobs	python -m src.cli dlq list
Retry       DLQ Job	    python -m src.cli dlq retry <job-id>

## üß™ Validation & Demo Scenarios

To demonstrate QueueCTL‚Äôs functionality, open two terminals:

CMD A ‚Üí for running workers

CMD B ‚Üí for managing jobs

Below are three core scenarios that showcase the system‚Äôs capabilities.

## ‚ñ∂Ô∏è Scenario 1: Basic Job Completion

Purpose:
Demonstrate successful job processing and transition from pending ‚Üí completed.

Explanation:
A simple command (echo Success) is enqueued.
The worker fetches the pending job, executes it, and marks it as completed in the database.

Commands:

Terminal	Command
CMD B	echo '{"id":"S1-success","command":"echo Success in Parallel"}' | python -m src.cli enqueue
CMD A	python -m src.cli worker start --count 1
CMD B	python -m src.cli status

Expected Output:

Job S1-success transitions from pending ‚Üí processing ‚Üí completed.

Worker logs show successful job execution.

## ‚ö†Ô∏è Scenario 2: Retry, Exponential Backoff, and DLQ

Purpose:
Show how failed jobs retry automatically using exponential backoff and move to DLQ when retries exceed the limit.

Explanation:
A failing command (exit 1) is enqueued.
The system retries based on configured max_retries and back_off_base.
After exhausting retries, the job moves to the Dead Letter Queue (DLQ).

Commands:

Terminal	Command
CMD B	python -m src.cli config set max-retries 1
CMD B	python -m src.cli config set back-off-base 3
CMD B	echo '{"id":"S2-fail","command":"exit 1"}' | python -m src.cli enqueue
CMD A	python -m src.cli worker start --count 1
CMD B	python -m src.cli dlq list
CMD B	python -m src.cli dlq retry S2-fail

Expected Output:

Job retries once, waiting 3^attempts seconds between tries.

After final failure, job appears in DLQ via python -m src.cli dlq list.

Retrying DLQ job re-enqueues it successfully.

## ‚öôÔ∏è Scenario 3: Concurrency Safety & Parallel Execution

Purpose:
Prove multiple workers can process different jobs concurrently without duplicate acquisition.

Explanation:
Two long-running jobs (ping commands) are enqueued.
Two worker processes execute them in parallel, ensuring no overlap or race condition occurs.

Commands:

Terminal	Command
CMD B	echo '{"id":"S3-A","command":"ping -n 7 127.0.0.1 > NUL"}' | python -m src.cli enqueue
CMD B	echo '{"id":"S3-B","command":"ping -n 7 127.0.0.1 > NUL"}' | python -m src.cli enqueue
CMD A	python -m src.cli worker start --count 2
CMD B	python -m src.cli status

Expected Output:

Both jobs run simultaneously on different worker processes.

No duplicate job execution or missed state updates.

Status shows both jobs moving independently from processing ‚Üí completed.

### üíª Setup Instructions

### üß© Technologies Used
- **Python 3.10+**
- **Click** ‚Äî Command-line interface
- **SQLite3** ‚Äî Job persistence
- **Multiprocessing** ‚Äî Worker concurrency

---

### ‚öôÔ∏è Installation Steps

```bash
# Clone the repository
git clone https://github.com/Sreehitha03/queuectlflam.git
cd queuectlflam

# (Optional) Create & activate virtual environment
python -m venv .venv
. .\.venv\Scripts\activate  # For PowerShell

# Install dependencies
pip install -r requirements.txt